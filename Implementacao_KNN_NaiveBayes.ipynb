{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementar o algoritmo K-NN ou Naive-Bayes em linguagem python \n",
        "1. A sua implementação não pode utilizar nenhum modelo pré-implementado a partir bibliotecas de machine learning (tensorflow, keras, sklearn, pytorch, caffe, etc...)\n",
        "\n",
        "2. Comparar os resultados da sua implementação vs scikit-learn\n",
        "\n",
        "3. Considere diferentes hiperparametros na avaliação\n",
        "\n",
        "4. Análise criticamente em termos de taxa de acerto, matriz de confusão e tempo de execução\n",
        "\n",
        "5. Utilize ao menos dois datasets do scikit-learn ou kaggle: Titanic, Iris, Digits, etc.\n",
        "\n",
        "6. Entrega e avaliação\n",
        "\n",
        "<small>Jupyter (ipynb), executável na plataforma google colab. (Enviar o arquivo *.ipynb, não pode ser ser link)\n",
        "Além da códificação, o aluno deverá fornecer comentários e texto discutindo a sua implementação, bem como uma discussão dos resultados nas últimas células do Jupyter.\n",
        "Entrega via AVA somente\n",
        "Grupo de 03 pessoas (formados no ava)\n",
        "Avaliará os R.A's 2,3, conforme disposto no plano de ensino\n",
        "Este trabalho contabilizará 4 horas de TDE</small>\n",
        "\n"
      ],
      "metadata": {
        "id": "BS9dUT5vcFq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arrumando o dataset"
      ],
      "metadata": {
        "id": "xLgFC7xWdbdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # Importando numpy\n",
        "from sklearn import datasets # Importando os datasets que serao usados no projeto\n",
        "from sklearn.model_selection import train_test_split # Importando a separacao de treino e teste\n",
        "\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "X_iris = iris.data # Features\n",
        "y_iris = iris.target # Classificacao\n",
        "\n",
        "X_digits = digits.data # Features\n",
        "y_digits = digits.target # Classificacao\n",
        "\n",
        "# Separando a data em treino e teste\n",
        "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(\n",
        "    X_iris, y_iris, test_size=0.3, random_state=0\n",
        ") # random_state para padronizar o treinamento\n",
        "\n",
        "X_digits_train, X_digits_test, y_digits_train, y_digits_test = train_test_split(\n",
        "   X_digits, y_digits, test_size=0.3, random_state=0\n",
        ")"
      ],
      "metadata": {
        "id": "o2AjyrSedabT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN do scikit-learn"
      ],
      "metadata": {
        "id": "XvtFPS3Rvwlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "print(\"KNeighbors ScikitLearn\")\n",
        "quant_neighbors = len(np.unique(y_iris)) # Problema de Classificacao\n",
        "knn = KNeighborsClassifier(n_neighbors = quant_neighbors)\n",
        "# Treinando o modelo do Scikit\n",
        "knn.fit(X_iris_train, y_iris_train)\n",
        "# Classificacao do KNN\n",
        "y_iris_pred = knn.predict(X_iris_test)\n",
        "\n",
        "# Comparando a previsao com o resultado real\n",
        "print(\"\\nDataSet: Iris\")\n",
        "print(f\"Acertos: {(y_iris_test == y_iris_pred).sum()}\")\n",
        "print(f\"Erros: {(y_iris_test != y_iris_pred).sum()}\")\n",
        "print(f\"Quantidade de Amostras: {len(y_iris_test)}\")\n",
        "print(f\"Precisao: {(y_iris_test == y_iris_pred).sum() / len(y_iris_test)}\")\n",
        "\n",
        "# Fazendo a mesma coisa com o outro dataset\n",
        "quant_neighbors = len(np.unique(y_digits))\n",
        "knn = KNeighborsClassifier(n_neighbors = quant_neighbors)\n",
        "# Treinando o modelo com outros dados\n",
        "knn.fit(X_digits_train, y_digits_train)\n",
        "# Classificacao do Scikit\n",
        "y_digits_pred = knn.predict(X_digits_test)\n",
        "\n",
        "# Comparando a previsao com o resultado real\n",
        "print(\"\\nDataSet: Digits\")\n",
        "print(f\"Acertos: {(y_digits_test == y_digits_pred).sum()}\")\n",
        "print(f\"Erros: {(y_digits_test != y_digits_pred).sum()}\")\n",
        "print(f\"Quantidade de Amostras: {len(y_digits_test)}\")\n",
        "print(f\"Precisao: {(y_digits_test == y_digits_pred).sum() / len(y_digits_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAz3rRq9v3IT",
        "outputId": "9513b1ce-b6b3-4507-ef70-868a10611f71"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNeighbors ScikitLearn\n",
            "\n",
            "DataSet: Iris\n",
            "Acertos: 44\n",
            "Erros: 1\n",
            "Quantidade de Amostras: 45\n",
            "Precisao: 0.9777777777777777\n",
            "\n",
            "DataSet: Digits\n",
            "Acertos: 526\n",
            "Erros: 14\n",
            "Quantidade de Amostras: 540\n",
            "Precisao: 0.9740740740740741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes do scikit-learn"
      ],
      "metadata": {
        "id": "3bhuT2Vic8Ax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyMUPPkMb-0j",
        "outputId": "b8fc0f88-c930-4ec7-d96b-ffca263856a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataSet: Iris\n",
            "Acertos: 45\n",
            "Erros: 0\n",
            "Quantidade de Amostras: 45\n",
            "Precisao: 1.0\n",
            "\n",
            "DataSet: Digits\n",
            "Acertos: 445\n",
            "Erros: 95\n",
            "Quantidade de Amostras: 540\n",
            "Precisao: 0.8240740740740741\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "print(\"Naive Bayes ScikitLearn\")\n",
        "gnb = GaussianNB()\n",
        "# Treinando o modelo do Scikit\n",
        "gnb.fit(X_iris_train, y_iris_train)\n",
        "# Classificacao do Scikit\n",
        "y_iris_pred = gnb.predict(X_iris_test)\n",
        "\n",
        "# Comparando a previsao com o resultado real\n",
        "print(\"\\nDataSet: Iris\")\n",
        "print(f\"Acertos: {(y_iris_test == y_iris_pred).sum()}\")\n",
        "print(f\"Erros: {(y_iris_test != y_iris_pred).sum()}\")\n",
        "print(f\"Quantidade de Amostras: {len(y_iris_test)}\")\n",
        "print(f\"Precisao: {(y_iris_test == y_iris_pred).sum() / len(y_iris_test)}\")\n",
        "\n",
        "# Fazendo a mesma coisa com o outro dataset\n",
        "# Treinando o modelo com outros dados\n",
        "gnb.fit(X_digits_train, y_digits_train)\n",
        "# Classificacao do Scikit\n",
        "y_digits_pred = gnb.predict(X_digits_test)\n",
        "\n",
        "# Comparando a previsao com o resultado real\n",
        "print(\"\\nDataSet: Digits\")\n",
        "print(f\"Acertos: {(y_digits_test == y_digits_pred).sum()}\")\n",
        "print(f\"Erros: {(y_digits_test != y_digits_pred).sum()}\")\n",
        "print(f\"Quantidade de Amostras: {len(y_digits_test)}\")\n",
        "print(f\"Precisao: {(y_digits_test == y_digits_pred).sum() / len(y_digits_test)}\")"
      ]
    }
  ]
}
